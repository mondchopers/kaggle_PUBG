{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Tr8k-l8w6T4c",
        "p4H-EkbysSW5",
        "gtFkpsaF8ZlT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mondchopers/kaggle_PUBG/blob/master/Exploration.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "JmV024t5q4b3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PUBG Competition Data Exploration"
      ]
    },
    {
      "metadata": {
        "id": "QKAugjTqrKfw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading Kaggle API and Download data to Colab Storage"
      ]
    },
    {
      "metadata": {
        "id": "NeFCxw8AS_yF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install kaggle API, go to my Google Drive and get API key so that I can\n",
        "# access dataset\n",
        "# https://medium.com/@move37timm/d18645f93648\n",
        "\n",
        "!pip install kaggle\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)\n",
        "\n",
        "# Optional piece of code: sometime just need to put the key in the right place\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xl1bLSYxTH4N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # List current active competitions\n",
        "# !kaggle competitions list\n",
        "\n",
        "# # Download PUBG data\n",
        "# !kaggle competitions download -c pubg-finish-placement-prediction -p /content/kaggle\n",
        "\n",
        "# List down all files from PUBG competition\n",
        "import os\n",
        "os.chdir('/content/kaggle')\n",
        "!ls\n",
        "\n",
        "# # Unzip all files\n",
        "# for file in os.listdir():\n",
        "#   !unzip {file}\n",
        "# !ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RZDKUk1zuveJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "import gc\n",
        "\n",
        "print(tf.test.gpu_device_name())\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQoQorXZxP7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount Google Drive Storage to Store Models Later On\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tr8k-l8w6T4c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "metadata": {
        "id": "y3RlB_kU6Q_j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p4H-EkbysSW5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exploration"
      ]
    },
    {
      "metadata": {
        "id": "rYZmOKl6WQb5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dtypes = {\n",
        "        'Id'                : 'str',\n",
        "        'groupId'           : 'str',\n",
        "        'matchId'           : 'str',\n",
        "        'assists'           : 'uint8',\n",
        "        'boosts'            : 'uint8',\n",
        "        'damageDealt'       : 'float32',\n",
        "        'DBNOs'             : 'uint8',\n",
        "        'headshotKills'     : 'uint8', \n",
        "        'heals'             : 'uint8',    \n",
        "        'killPlace'         : 'uint8',    \n",
        "        'killPoints'        : 'uint8',    \n",
        "        'kills'             : 'uint8',    \n",
        "        'killStreaks'       : 'uint8',    \n",
        "        'longestKill'       : 'float32',    \n",
        "        'maxPlace'          : 'uint8',\n",
        "        'matchDuration'     : 'uint32',\n",
        "        'matchType'         : 'str',\n",
        "        'numGroups'         : 'uint8',\n",
        "        'rankPoints'        : 'int64',\n",
        "        'revives'           : 'uint8',    \n",
        "        'rideDistance'      : 'float32',    \n",
        "        'roadKills'         : 'uint8',    \n",
        "        'swimDistance'      : 'float32',    \n",
        "        'teamKills'         : 'uint8',    \n",
        "        'vehicleDestroys'   : 'uint8',    \n",
        "        'walkDistance'      : 'float32',    \n",
        "        'weaponsAcquired'   : 'uint8',    \n",
        "        'winPoints'         : 'uint8', \n",
        "        'winPlacePerc'      : 'float32' \n",
        "}\n",
        "\n",
        "df_train = pd.read_csv('train_V2.csv',dtype=dtypes)\n",
        "print('Training rows: ' + str(len(df_train)))\n",
        "# df_tests = pd.read_csv('test_V2.csv',dtype=dtypes)\n",
        "# print('Testing rows: ' + str(len(df_tests)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8x56XODiXjeP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Read training data, print out some information from there\n",
        "trainDf = pd.read_csv('train_V2.csv')\n",
        "print(trainDf.head(3))\n",
        "print(len(trainDf))\n",
        "print(trainDf.dtypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulIIPn2RXwbH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Going through groups and see how many players are inside each group\n",
        "for i in np.unique(trainDf['groupId'].values):\n",
        "  print(i, len(trainDf[trainDf['groupId'] == i]))\n",
        "  if i > 10:\n",
        "    break\n",
        "   \n",
        "print(trainDf[trainDf['groupId'] == 11])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtFkpsaF8ZlT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using XGB for Regression"
      ]
    },
    {
      "metadata": {
        "id": "zgv5D0lm4gEZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Explicitly choose columns for X and Y axis\n",
        "XCol = list(trainDf.columns)\n",
        "XCol.remove('Id')\n",
        "XCol.remove('groupId')\n",
        "XCol.remove('matchId')\n",
        "# Split into train and validation\n",
        "trainLen = int(0.75 * len(trainDf))\n",
        "seed = np.random.permutation(len(trainDf))\n",
        "\n",
        "trainX = trainDf[XCol].iloc[seed[trainLen:]].reset_index(drop=True)\n",
        "trainY = trainDf['winPlacePerc'].iloc[seed[trainLen:]].reset_index(drop=True)\n",
        "validX = trainDf[XCol].iloc[seed[:trainLen]].reset_index(drop=True)\n",
        "validY = trainDf['winPlacePerc'].iloc[seed[:trainLen]].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l1ajsDTTFxar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = xgb.XGBRegressor(n_estimators=50, learning_rate=0.01, subsample=0.75,\n",
        "                           colsample_bytree=1, max_depth=4)\n",
        "model.fit(trainX, trainY)\n",
        "print(model.score(validX, validY))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GgWgSL5sJxUu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "validZ = model.predict(validX)\n",
        "print(validZ[0], validY.values[0])\n",
        "plt.scatter(validY.values, validZ-validY.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BNJ2wj8lZQNW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stephen's Code"
      ]
    },
    {
      "metadata": {
        "id": "GeJ5h42TU6WO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Differentiation between data with rankPoints (old API) and without (new API)\n",
        "\n",
        "print(len(df_train[df_train['rankPoints'] < 0]))\n",
        "print(len(df_train[df_train['rankPoints'] >= 0]))\n",
        "print(len(df_train))\n",
        "\n",
        "# print(len(df_tests[df_tests['rankPoints'] < 0]))\n",
        "# print(len(df_tests[df_tests['rankPoints'] >= 0]))\n",
        "# print(len(df_tests))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "csppmaUMLMpN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dtypes = {\n",
        "        'Id'                : 'str',\n",
        "        'groupId'           : 'str',\n",
        "        'matchId'           : 'str',\n",
        "        'assists'           : 'uint8',\n",
        "        'boosts'            : 'uint8',\n",
        "        'damageDealt'       : 'float32',\n",
        "        'DBNOs'             : 'uint8',\n",
        "        'headshotKills'     : 'uint8', \n",
        "        'heals'             : 'uint8',    \n",
        "        'killPlace'         : 'uint8',    \n",
        "        'killPoints'        : 'uint8',    \n",
        "        'kills'             : 'uint8',    \n",
        "        'killStreaks'       : 'uint8',    \n",
        "        'longestKill'       : 'float32',    \n",
        "        'maxPlace'          : 'uint8',\n",
        "        'matchDuration'     : 'uint32',\n",
        "        'matchType'         : 'str',\n",
        "        'numGroups'         : 'uint8',\n",
        "        'rankPoints'        : 'int64',\n",
        "        'revives'           : 'uint8',    \n",
        "        'rideDistance'      : 'float32',    \n",
        "        'roadKills'         : 'uint8',    \n",
        "        'swimDistance'      : 'float32',    \n",
        "        'teamKills'         : 'uint8',    \n",
        "        'vehicleDestroys'   : 'uint8',    \n",
        "        'walkDistance'      : 'float32',    \n",
        "        'weaponsAcquired'   : 'uint8',    \n",
        "        'winPoints'         : 'uint8', \n",
        "        'winPlacePerc'      : 'float32' \n",
        "}\n",
        "\n",
        "df_train = pd.read_csv('train_V2.csv',dtype=dtypes)\n",
        "print('Training rows: ' + str(len(df_train)))\n",
        "print(len(df_train.columns), df_train.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jRKKsqejalCj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Constructing Full Data Frame with some additional feature shaping\n",
        "# Firstly, seperate columns into objective data like damage stats (mean columns)\n",
        "# Then compute group&match mean, group std and group size as features\n",
        "# and append to full df\n",
        "\n",
        "# Using new API, filter for rankPoints < 0\n",
        "df_train = df_train[df_train['rankPoints'] < 0]\n",
        "mean_columns = list(df_train.columns)\n",
        "mean_columns.remove('rankPoints')\n",
        "print(len(mean_columns), mean_columns)\n",
        "\n",
        "# # Using old API, filter for rankPoints >= 0\n",
        "# df_train = df_train[df_train['rankPoints'] >= 0]\n",
        "# mean_columns = list(df_train.columns)\n",
        "# mean_columns.remove('killPoints')\n",
        "# mean_columns.remove('winPoints')\n",
        "# print(len(mean_columns), mean_columns)\n",
        "\n",
        "match_columns = ['Id', 'matchId','groupId', 'maxPlace', 'numGroups', 'winPlacePerc']\n",
        "_ = [mean_columns.remove(x) for x in match_columns]\n",
        "print(len(mean_columns), mean_columns)\n",
        "_ = [mean_columns.remove(x) for x in ['longestKill']]\n",
        "target = 'winPlacePerc'\n",
        "print(mean_columns)\n",
        "print(match_columns)\n",
        "print(target)\n",
        "\n",
        "df_full = df_train[match_columns].drop_duplicates()\n",
        "print(len(df_full.columns), df_full.columns)\n",
        "df_groups = df_train.groupby(['matchId','groupId'])\n",
        "del df_train\n",
        "gc.collect()\n",
        "\n",
        "# Group & match mean data\n",
        "df_groups_mean = df_groups[mean_columns].mean().fillna(0).add_suffix('_mean').reset_index()\n",
        "print(len(df_groups_mean.columns), df_groups_mean.columns)\n",
        "df_match_pct = df_groups_mean.groupby(['matchId']).rank(pct=True).add_suffix('_match_pct')\n",
        "df_groups_mean[list(df_match_pct.columns)] = df_match_pct\n",
        "print(len(df_groups_mean.columns), df_groups_mean.columns)\n",
        "df_match_mean = df_groups_mean.groupby(['matchId']).mean().fillna(0).add_suffix('_match_mean').reset_index()\n",
        "df_match_std = df_groups_mean.groupby(['matchId']).std().fillna(0).add_suffix('_match_std').reset_index()\n",
        "df_full = df_full.merge(df_groups_mean,how='left',on=['matchId','groupId'])\n",
        "df_full = df_full.merge(df_match_mean,how='left',on=['matchId'])\n",
        "df_full = df_full.merge(df_match_std,how='left',on=['matchId'])\n",
        "del df_match_pct\n",
        "del df_groups_mean\n",
        "del df_match_mean\n",
        "del df_match_std\n",
        "gc.collect()\n",
        "print(len(df_full.columns), df_full.columns)\n",
        "\n",
        "# # Group std and count data\n",
        "df_groups_std = df_groups[mean_columns].std().fillna(0).add_suffix('_std').reset_index()\n",
        "df_groups_size = df_groups.size().reset_index(name='group_size')\n",
        "df_full = df_full.merge(df_groups_std,how='left',on=['matchId','groupId'])\n",
        "df_full = df_full.merge(df_groups_size,how='left',on=['matchId','groupId'])\n",
        "del df_groups\n",
        "del df_groups_std\n",
        "del df_groups_size\n",
        "gc.collect()\n",
        "print(df_full.head())\n",
        "print(list(df_full.columns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UredVYAknXLr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Constructing X and Y matrices\n",
        "\n",
        "# Filtering through the columns to be used\n",
        "feature_columns = list(df_full.columns)\n",
        "print(len(feature_columns), feature_columns)\n",
        "for item in match_columns:\n",
        "  feature_columns.remove(item)\n",
        "print(len(feature_columns), feature_columns)\n",
        "train_x = df_full[feature_columns].values\n",
        "train_y = df_full[target].values\n",
        "del df_full\n",
        "gc.collect()\n",
        "\n",
        "# Shuffling\n",
        "order = np.argsort(np.random.random(train_y.shape))\n",
        "train_x = train_x[order]\n",
        "train_y = train_y[order]\n",
        "\n",
        "# Normalize Training Data\n",
        "train_mean = train_x.mean(axis=0)\n",
        "train_std = train_x.std(axis=0)\n",
        "train_x = (train_x - train_mean) / train_std\n",
        "train_x = np.nan_to_num(train_x)\n",
        "\n",
        "print(train_x.shape, train_y.shape)\n",
        "print(train_x[0,:]) # first X example\n",
        "print(train_y[0]) # first Y example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NBkDhcDHs2h1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Neural Network Model\n",
        "\n",
        "def build_model(inputShape):\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Dense(256, activation=tf.nn.relu,\n",
        "                       input_shape=inputShape),\n",
        "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(8, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.train.RMSPropOptimizer(0.001)\n",
        "#   optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "model = build_model(inputShape=(train_x.shape[1],))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hRyt-ygtwbb6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "def plot_history(history, saveLoc=''):\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [1000$]')\n",
        "  plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),\n",
        "           label='Train Loss')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n",
        "           label = 'Val loss')\n",
        "  plt.legend()\n",
        "#   plt.ylim([0, .02])\n",
        "  \n",
        "  # Save Plot\n",
        "  if len(saveLoc) > 0:\n",
        "    plt.savefig(saveLoc)\n",
        "    \n",
        "def save_history(history, saveLoc):\n",
        "  historyDf = pd.DataFrame()\n",
        "  historyDf = historyDf.assign(Epoch = np.array(history.epoch))\n",
        "  for el in history.history.keys():\n",
        "    historyDf = historyDf.assign(**{el : history.history[el]})\n",
        "  historyDf = historyDf.set_index('Epoch')\n",
        "  historyDf.to_csv(saveLoc)\n",
        "\n",
        "# Display training progress by printing a single dot for each completed epoch\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 10 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 60\n",
        "gdrive = '/content/gdrive/My Drive/Colab Notebooks/Kaggle_PUBG/'\n",
        "modelName = 'Kaggle_PUBG_model_new_001'\n",
        "\n",
        "# Saving model normalization:\n",
        "with open(gdrive + modelName + '_params.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "    pickle.dump([train_mean, train_std], f)\n",
        "\n",
        "# Store training stats\n",
        "history = model.fit(train_x, train_y, epochs=EPOCHS,\n",
        "                    validation_split=0.2, verbose=1, batch_size=512)\n",
        "plot_history(history)\n",
        "\n",
        "# Saving model\n",
        "model.save(gdrive + modelName + '.h5')\n",
        "\n",
        "# Saving history\n",
        "save_history(history, gdrive + modelName + '.png' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4of1vqyD9Rgt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Checking model prediction\n",
        "print(model.predict(train_x[0, :].reshape(1, -1)), train_y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2sbNEq_8xGEk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reload Model\n",
        "\n",
        "loaded_model = keras.models.load_model('/content/gdrive/My Drive/Colab Notebooks/kaggle_PUBG_model_new_001.h5')\n",
        "\n",
        "optimizer = tf.train.RMSPropOptimizer(0.001)\n",
        "loaded_model.compile(loss='mse',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['mae'])\n",
        "\n",
        "# Store training stats\n",
        "history = model.fit(train_data, train_labels, epochs=2,\n",
        "                    validation_split=0.2, verbose=1, batch_size = 128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nAhj8Dk2LlE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Making Prediction"
      ]
    },
    {
      "metadata": {
        "id": "YbLFXF083AFK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dtypes = {\n",
        "        'Id'                : 'str',\n",
        "        'groupId'           : 'str',\n",
        "        'matchId'           : 'str',\n",
        "        'assists'           : 'uint8',\n",
        "        'boosts'            : 'uint8',\n",
        "        'damageDealt'       : 'float32',\n",
        "        'DBNOs'             : 'uint8',\n",
        "        'headshotKills'     : 'uint8', \n",
        "        'heals'             : 'uint8',    \n",
        "        'killPlace'         : 'uint8',    \n",
        "        'killPoints'        : 'uint8',    \n",
        "        'kills'             : 'uint8',    \n",
        "        'killStreaks'       : 'uint8',    \n",
        "        'longestKill'       : 'float32',    \n",
        "        'maxPlace'          : 'uint8',\n",
        "        'matchDuration'     : 'uint32',\n",
        "        'matchType'         : 'str',\n",
        "        'numGroups'         : 'uint8',\n",
        "        'rankPoints'        : 'int64',\n",
        "        'revives'           : 'uint8',    \n",
        "        'rideDistance'      : 'float32',    \n",
        "        'roadKills'         : 'uint8',    \n",
        "        'swimDistance'      : 'float32',    \n",
        "        'teamKills'         : 'uint8',    \n",
        "        'vehicleDestroys'   : 'uint8',    \n",
        "        'walkDistance'      : 'float32',    \n",
        "        'weaponsAcquired'   : 'uint8',    \n",
        "        'winPoints'         : 'uint8', \n",
        "        'winPlacePerc'      : 'float32' \n",
        "}\n",
        "\n",
        "df_tests = pd.read_csv('test_V2.csv', dtype=dtypes)\n",
        "print('Testing rows: ' + str(len(df_tests)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ed5QNHLh5blT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_tests['Status'] = df_tests['rankPoints'] >= 0\n",
        "print(df_tests.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DAZt7RMH3Kch",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "gdrive = '/content/gdrive/My Drive/Colab Notebooks/Kaggle_PUBG/'\n",
        "modelName = 'Kaggle_PUBG_model_new_001'\n",
        "\n",
        "# Using new API, filter for rankPoints < 0\n",
        "df_tests = df_tests[df_tests['rankPoints'] < 0]\n",
        "mean_columns = list(df_tests.columns)\n",
        "mean_columns.remove('rankPoints')\n",
        "\n",
        "# # Using old API, filter for rankPoints >= 0\n",
        "# df_tests = df_tests[df_tests['rankPoints'] >= 0]\n",
        "# print(len(df_tests.columns), df_tests.columns)\n",
        "# mean_columns = list(df_tests.columns)\n",
        "# mean_columns.remove('killPoints')\n",
        "# mean_columns.remove('winPoints')\n",
        "\n",
        "match_columns = ['Id', 'matchId','groupId', 'maxPlace', 'numGroups']\n",
        "_ = [mean_columns.remove(x) for x in match_columns]\n",
        "print(len(mean_columns), mean_columns)\n",
        "_ = [mean_columns.remove(x) for x in ['longestKill']]\n",
        "target = 'Id'\n",
        "print(mean_columns)\n",
        "print(match_columns)\n",
        "print(target)\n",
        "\n",
        "df_full = df_tests[match_columns].drop_duplicates()\n",
        "print(len(df_full.columns), df_full.columns)\n",
        "df_groups = df_tests.groupby(['matchId','groupId'])\n",
        "del df_tests\n",
        "gc.collect()\n",
        "\n",
        "# Group & match mean data\n",
        "df_groups_mean = df_groups[mean_columns].mean().fillna(0).add_suffix('_mean').reset_index()\n",
        "df_match_pct = df_groups_mean.groupby(['matchId']).rank(pct=True).add_suffix('_match_pct')\n",
        "df_groups_mean[list(df_match_pct.columns)] = df_match_pct\n",
        "df_match_mean = df_groups_mean.groupby(['matchId']).mean().fillna(0).add_suffix('_match_mean').reset_index()\n",
        "df_match_std = df_groups_mean.groupby(['matchId']).std().fillna(0).add_suffix('_match_std').reset_index()\n",
        "df_full = df_full.merge(df_groups_mean,how='left',on=['matchId','groupId'])\n",
        "df_full = df_full.merge(df_match_mean,how='left',on=['matchId'])\n",
        "df_full = df_full.merge(df_match_std,how='left',on=['matchId'])\n",
        "del df_match_pct\n",
        "del df_groups_mean\n",
        "del df_match_mean\n",
        "del df_match_std\n",
        "gc.collect()\n",
        "print(len(df_full.columns), df_full.columns)\n",
        "\n",
        "# # Group std and count data\n",
        "df_groups_std = df_groups[mean_columns].std().fillna(0).add_suffix('_std').reset_index()\n",
        "df_groups_size = df_groups.size().reset_index(name='group_size')\n",
        "df_full = df_full.merge(df_groups_std,how='left',on=['matchId','groupId'])\n",
        "df_full = df_full.merge(df_groups_size,how='left',on=['matchId','groupId'])\n",
        "del df_groups\n",
        "del df_groups_std\n",
        "del df_groups_size\n",
        "gc.collect()\n",
        "print(df_full.head())\n",
        "print(list(df_full.columns))\n",
        "\n",
        "# Construct tests x\n",
        "feature_columns = list(df_full.columns)\n",
        "print(len(feature_columns), feature_columns)\n",
        "for item in match_columns:\n",
        "  feature_columns.remove(item)\n",
        "print(len(feature_columns), feature_columns)\n",
        "tests_x = df_full[feature_columns].values\n",
        "tests_z = df_full[target].values\n",
        "print(tests_x.shape, tests_z.shape)\n",
        "del df_full\n",
        "gc.collect()\n",
        "\n",
        "# Normalize Training Data\n",
        "with open(gdrive + modelName + '_params.pkl', 'rb') as f:  # Python 3: open(..., 'wb')\n",
        "    [train_mean, train_std] = pickle.load(f)\n",
        "tests_x = (tests_x - train_mean) / train_std\n",
        "tests_x = np.nan_to_num(tests_x)\n",
        "\n",
        "# Make prediction\n",
        "model = keras.models.load_model(gdrive + modelName + '.h5')\n",
        "tests_y = model.predict(tests_x)\n",
        "print(tests_y.shape)\n",
        "\n",
        "# Construct Prediction DataFrame and Save Result\n",
        "tests_result_df = pd.DataFrame()\n",
        "tests_result_df['Id'] = tests_z\n",
        "tests_result_df['winPlacePerc'] = tests_y\n",
        "print(tests_result_df.head())\n",
        "print(len(tests_result_df))\n",
        "tests_result_df.to_csv(gdrive + modelName + '_result.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AwB64T_5rOQG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}